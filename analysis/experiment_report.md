# Turing Game Experiment Results

## Overall Model Performance

- **gemini-1.5-pro**: 26.7% (16/60)

## Performance by File


### gemini-1.5-pro

- **Day_1_Ivy.md**: 20.0% accuracy
- **Day_1_Hal.md**: 30.0% accuracy
- **Day_1_Gus.md**: 30.0% accuracy
- **Day_1_Kim.md**: 30.0% accuracy
- **Day_1_Jan.md**: 30.0% accuracy
- **Day_1_Leo.md**: 20.0% accuracy

## Most Challenging Games

The following games were the most difficult for models to correctly identify the bot:
- Game 1003
- Game 1702
- Game 1503
- Game 1303
- Game 1501

## Easiest Games

The following games were the easiest for models to correctly identify the bot:
- Game 1001
- Game 1801
- Game 1902

## Conclusion

The models struggled to reliably detect bots beyond random chance (33.33%).