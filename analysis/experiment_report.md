# Turing Game Experiment Results

## Overall Model Performance

- **claude-3-5-sonnet-20240620**: 44.4% (20/45)

## Performance by File


### claude-3-5-sonnet-20240620

- **Day_1_Hal.md**: 14.3% accuracy
- **Day_1_Gus.md**: 62.5% accuracy
- **Day_1_Kim.md**: 50.0% accuracy
- **Day_1_Jan.md**: 50.0% accuracy
- **Day_1_Leo.md**: 40.0% accuracy

## Most Challenging Games

The following games were the most difficult for models to correctly identify the bot:
- Game 1403
- Game 1102
- Game 1202
- Game 1601
- Game 1703

## Easiest Games

The following games were the easiest for models to correctly identify the bot:
- Game 1402
- Game 1801
- Game 1803
- Game 1503
- Game 1501

## Conclusion

The models performed better than random chance (33.33%) at detecting bots, but with moderate success.